{
 "metadata": {
  "name": "",
  "signature": "sha256:f3f2623ebcea6339c223c8de2e676cab0e397562cbfd6452f686438f00b26e77"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "import datetime as dt\n",
      "import pywt\n",
      "from sklearn.decomposition import MiniBatchDictionaryLearning, dict_learning_online\n",
      "from sklearn.feature_extraction.image import extract_patches_2d \n",
      "from sklearn.decomposition import fastica\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train = pd.read_csv('data/train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_train.dropna(inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = df_train.columns\n",
      "features  = features.drop('label')\n",
      "target = 'label'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_X = df_train[features].values\n",
      "training_y = df_train[target].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import classification_report, roc_auc_score \n",
      "# X_split1, X_split2, y_split1, y_split2 = train_test_split(training_X, training_y, test_size=0.50)\n",
      "# del training_X, training_y\n",
      "X_train, X_test, y_train, y_test = train_test_split(training_X, training_y, test_size=0.30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB \n",
      "\n",
      "MNB = MultinomialNB()\n",
      "MNB.fit(X_train ,y_train)\n",
      "y_predict_train = MNB.predict(X_train )\n",
      "y_predict_test = MNB.predict(X_test )\n",
      "print 'R^2 train: ' + str(MNB.score(X_train ,y_train))\n",
      "print 'R^2 test: ' + str(MNB.score(X_test ,y_test))\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "# auc1= roc_auc_score(y_train, y_predict_train)\n",
      "# auc2= roc_auc_score(y_test, y_predict_test)\n",
      "# print 'Area Under Curve train: ' + str(auc1)\n",
      "# print 'Area Under Curve test: ' + str(auc2)\n",
      "# print 'Area Under Curve average: ' + str((auc1+auc2)/2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2 train: 0.826336952151\n",
        "R^2 test: 0.829346092504\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.92      0.91      0.92      2434\n",
        "          1       0.89      0.93      0.91      2747\n",
        "          2       0.88      0.83      0.86      2500\n",
        "          3       0.78      0.81      0.79      2571\n",
        "          4       0.83      0.75      0.79      2387\n",
        "          5       0.86      0.66      0.74      2294\n",
        "          6       0.88      0.92      0.90      2449\n",
        "          7       0.94      0.82      0.88      2589\n",
        "          8       0.66      0.79      0.72      2429\n",
        "          9       0.69      0.82      0.75      2470\n",
        "\n",
        "avg / total       0.83      0.83      0.83     24870\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.93      0.91      0.92      1034\n",
        "          1       0.90      0.93      0.91      1207\n",
        "          2       0.88      0.84      0.86      1065\n",
        "          3       0.81      0.80      0.81      1104\n",
        "          4       0.82      0.74      0.78      1032\n",
        "          5       0.85      0.66      0.74       939\n",
        "          6       0.88      0.91      0.89      1036\n",
        "          7       0.95      0.82      0.88      1160\n",
        "          8       0.65      0.79      0.72       997\n",
        "          9       0.70      0.85      0.77      1085\n",
        "\n",
        "avg / total       0.84      0.83      0.83     10659\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier  \n",
      "RF = RandomForestClassifier(max_depth=8)\n",
      "\n",
      "\n",
      "RF.fit(X_train,y_train)\n",
      "y_predict_train = RF.predict(X_train)\n",
      "y_predict_test = RF.predict(X_test)  \n",
      "print RF.score(X_train,y_train)\n",
      "print RF.score(X_test,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.914676316848\n",
        "0.896050286143"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.97      0.98      0.97      2434\n",
        "          1       0.94      0.98      0.96      2747\n",
        "          2       0.93      0.90      0.92      2500\n",
        "          3       0.88      0.88      0.88      2571\n",
        "          4       0.90      0.88      0.89      2387\n",
        "          5       0.92      0.85      0.89      2294\n",
        "          6       0.94      0.97      0.95      2449\n",
        "          7       0.93      0.93      0.93      2589\n",
        "          8       0.89      0.90      0.90      2429\n",
        "          9       0.84      0.87      0.86      2470\n",
        "\n",
        "avg / total       0.91      0.91      0.91     24870\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.96      0.97      0.96      1034\n",
        "          1       0.93      0.97      0.95      1207\n",
        "          2       0.89      0.89      0.89      1065\n",
        "          3       0.86      0.86      0.86      1104\n",
        "          4       0.90      0.87      0.88      1032\n",
        "          5       0.89      0.80      0.85       939\n",
        "          6       0.92      0.93      0.93      1036\n",
        "          7       0.93      0.89      0.91      1160\n",
        "          8       0.86      0.86      0.86       997\n",
        "          9       0.82      0.89      0.85      1085\n",
        "\n",
        "avg / total       0.90      0.90      0.90     10659\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = pd.read_csv('data/test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_X = df_test[features]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict_y = RF.predict(test_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_answer = pd.DataFrame(data=predict_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_answer.rename(columns={0: 'Label'}, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_answer['ImageId'] = range(1,len(predict_y)+1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_answer = df_answer.reindex_axis(['ImageId','Label'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_answer.to_csv('submission.csv',index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}